{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `014` Attention mechanisms\n",
    "\n",
    "Requirements: 010 Embeddings, 013 LSTM\n",
    "\n",
    "⚠️ WIP\n",
    "\n",
    "There is a fundamental problem with LSTM, GRU and other RNNs, which is that they are not feedforward, so that the individual timesteps of processing a sequence cannot be parallelized. This is a problem because it makes the training slow. Plus, the RNNs are not very good at capturing very long-term dependencies.\n",
    "\n",
    "There is a different kind of layer called `Attention` that can be used to solve this problem. The idea is to have a layer that can look at the entire sequence at once and decide which parts of the sequence are important for the current timestep. This way, the layer can be parallelized and can capture long-term dependencies. The underlying idea is converting every element in the sequence into a linear combination of all the elements in the sequence, with the weights of the linear combination being learned. Let's see an implementation in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from matplotlib import pyplot as plt\n",
    "from string import ascii_letters, digits\n",
    "from time import time\n",
    "from unicodedata import category, normalize\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vocabulary = ascii_letters + digits + ' .,;\\'!'\n",
    "c2i = {c: i for i, c in enumerate(vocabulary)}\n",
    "i2c = {i: c for i, c in enumerate(vocabulary)}\n",
    "\n",
    "def vectorize_sentence(s):\n",
    "\treturn [c2i[c] for c in normalize('NFD', s) if category(c) != 'Mn' and c in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([vectorize_sentence('Hello, World!')])\n",
    "\n",
    "embedding_channels = 8\n",
    "embeddings = torch.randn(len(vocabulary), embedding_channels)\n",
    "input = embeddings[input]\n",
    "\n",
    "head_size = 16\n",
    "W_q = torch.randn(embedding_channels, head_size)\n",
    "W_k = torch.randn(embedding_channels, head_size)\n",
    "W_v = torch.randn(embedding_channels, head_size)\n",
    "\n",
    "q = input @ W_q\n",
    "k = input @ W_k\n",
    "attention_weights = q @ k.transpose(-2, -1).softmax(dim=-1)\n",
    "\n",
    "v = input @ W_v\n",
    "output = attention_weights @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
