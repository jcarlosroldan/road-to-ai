{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `014` Attention mechanisms\n",
    "\n",
    "Requirements: 010 Embeddings, 013 LSTM\n",
    "\n",
    "⚠️ WIP\n",
    "\n",
    "There is a fundamental problem with LSTM, GRU and other RNNs, which is that they are not feedforward, so that the individual timesteps of processing a sequence cannot be parallelized. This time dependency makes training slower. RNNs typically capture dependencies 100\n",
    "\n",
    "There is a different kind of layer called `Attention` that can be used to solve this problem. The idea is to have a layer that can look at the entire sequence at once and decide which parts of the sequence are important for the current timestep. This way, the layer can be parallelized and can capture long-term dependencies. The underlying idea is converting every element in the sequence into a linear combination of all the elements in the sequence, with the weights of the linear combination being learned. Let's see an implementation in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from matplotlib import pyplot as plt\n",
    "from string import ascii_letters, digits\n",
    "from time import time\n",
    "from unicodedata import category, normalize\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vocabulary = ascii_letters + digits + ' .,;\\'!'\n",
    "c2i = {c: i for i, c in enumerate(vocabulary)}\n",
    "i2c = {i: c for i, c in enumerate(vocabulary)}\n",
    "\n",
    "def vectorize_sentence(s):\n",
    "\treturn [c2i[c] for c in normalize('NFD', s) if category(c) != 'Mn' and c in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([vectorize_sentence('Hello, World!')])  # (batch_size=1, context_length=13)\n",
    "\n",
    "embedding_channels = 8\n",
    "embeddings = torch.randn(len(vocabulary), embedding_channels)  # (vocabulary_size, embedding_channels=8)\n",
    "input = embeddings[input]  # (batch_size=1, context_length=13, embedding_channels=8)\n",
    "\n",
    "head_size = 16\n",
    "# query space mapping: what each token is looking for\n",
    "W_q = torch.randn(embedding_channels, head_size)  # (embedding_channels=8, head_size=16)\n",
    "# key space mapping: what each has to offer\n",
    "W_k = torch.randn(embedding_channels, head_size)  # (embedding_channels=8, head_size=16)\n",
    "\n",
    "q = input @ W_q  # (batch_size=1, context_length=13, head_size=16)\n",
    "k = input @ W_k  # (batch_size=1, context_length=13, head_size=16)\n",
    "\n",
    "# dot product of what each token is looking for and what each has to offer -> attention weights: how much each token should pay attention to each other token\n",
    "# note that you swap the last two dimensions of k to make a square matrix of dot products\n",
    "attention_weights = (q @ k.transpose(-2, -1)).softmax(dim=-1)  # (batch_size=1, context_length=13, context_length=13)\n",
    "\n",
    "# value space: what each token is contributing\n",
    "W_v = torch.randn(embedding_channels, head_size)  # (embedding_channels=8, head_size=16)\n",
    "\n",
    "v = input @ W_v  # (batch_size=1, context_length=13, head_size=16)\n",
    "\n",
    "# weighted sum of what each token is contributing, based on how much each token should pay attention to each other token\n",
    "output = attention_weights @ v  # (batch_size=1, context_length=13, head_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttention(torch.nn.Module):\n",
    "\tdef __init__(self, embedding_channels, head_size):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.W_q = torch.nn.Parameter(torch.randn(embedding_channels, head_size))\n",
    "\t\tself.W_k = torch.nn.Parameter(torch.randn(embedding_channels, head_size))\n",
    "\t\tself.W_v = torch.nn.Parameter(torch.randn(embedding_channels, head_size))\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tq = input @ self.W_q\n",
    "\t\tk = input @ self.W_k\n",
    "\t\tv = input @ self.W_v\n",
    "\t\tattention_weights = (q @ k.transpose(-2, -1)).softmax(dim=-1)\n",
    "\t\treturn attention_weights @ v\n",
    "\t\n",
    "class DigitClassifier(torch.nn.Module):\n",
    "\tdef __init__(self, vocabulary_size, embedding_channels, head_size):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.embedding = torch.nn.Embedding(vocabulary_size, embedding_channels)\n",
    "\t\tself.attention = SimpleAttention(embedding_channels, head_size)\n",
    "\t\tself.fc = torch.nn.Linear(head_size, 10)\n",
    "\t\n",
    "\tdef forward(self, input):\n",
    "\t\tembedding = self.embedding(input)\n",
    "\t\tattention = self.attention(embedding)\n",
    "\t\treturn self.fc(attention.mean(dim=1))\n",
    "\n",
    "model = DigitClassifier(len(vocabulary), 8, 16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6752415 sentences from 8 languages using 68 different characters\n",
      "tensor([ 1, 24, 62, 45,  0, 13,  6, 62, 51,  0,  8, 24,  0, 13,  6, 64]) tensor(4) -> by Tang Zaiyang, en\n"
     ]
    }
   ],
   "source": [
    "with open('custom-data/sentences.json', encoding='utf-8') as f:\n",
    "\tdata = loads(f.read())\n",
    "\n",
    "languages = list(data.keys())\n",
    "\n",
    "X, Y = [], []\n",
    "sentence_size = 16\n",
    "for language, sentences in data.items():\n",
    "\tfor sentence in sentences:\n",
    "\t\tsentence = vectorize_sentence(sentence)\n",
    "\t\tfor i in range(len(sentence) - sentence_size + 1):\n",
    "\t\t\tX.append(sentence[i:i+sentence_size])\n",
    "\t\t\tY.append(languages.index(language))\n",
    "ix = torch.randperm(len(X))\n",
    "X = torch.tensor([X[i] for i in ix], device=device)\n",
    "Y = torch.tensor([Y[i] for i in ix], device=device)\n",
    "\n",
    "print(f'Loaded {len(X)} sentences from {len(languages)} languages using {len(vocabulary)} different characters')\n",
    "print(X[0], Y[0], '->', ''.join(i2c[i.item()] for i in X[0]), languages[Y[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4104,  0.2441, -1.0296,  0.5545,  0.7851, -0.5065, -0.4514, -0.9293,\n",
       "         1.0055,  0.2061], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
