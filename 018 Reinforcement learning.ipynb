{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `018` Reinforcement Learning\n",
    "\n",
    "Requirements: 016 Transformers\n",
    "\n",
    "⚡⚡⚡⚡WIP⚡⚡⚡⚡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from random import choice\n",
    "\n",
    "device = torch.device('cuda' if torch.backends.cudnn.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_board():\n",
    "\treturn torch.tensor([[0] * 4 for _ in range(4)], device=device)\n",
    "\n",
    "LEFT, UP, RIGHT, DOWN = 0, 1, 2, 3\n",
    "\n",
    "def push(board, towards):\n",
    "\tres = board.rot90(towards)  # this way we always push towards the left\n",
    "\tzeroes = []\n",
    "\tfor r, row in enumerate(res):\n",
    "\t\tres[r] = _push_row_left(row)\n",
    "\t\tzeroes.extend((r, c) for c, n in enumerate(res[r]) if n == 0)\n",
    "\tif zeroes:\n",
    "\t\tr, c = choice(zeroes)\n",
    "\t\tres[r, c] = 1 if torch.rand(1) < 0.9 else 2\n",
    "\tres = res.rot90(-towards)\n",
    "\tchanged = res.ne(board).any().item()\n",
    "\treturn res, changed\n",
    "\n",
    "def _push_row_left(row):\n",
    "\tnew_row = []\n",
    "\tlast_compressed = False\n",
    "\tfor tile in map(int, list(row)):\n",
    "\t\tif tile == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tif len(new_row) and new_row[-1] == tile and not last_compressed:\n",
    "\t\t\tnew_row[-1] += 1\n",
    "\t\t\tlast_compressed = True\n",
    "\t\telse:\n",
    "\t\t\tnew_row.append(tile)\n",
    "\t\t\tlast_compressed = False\n",
    "\twhile len(new_row) < 4: new_row.append(0)\n",
    "\treturn torch.tensor(new_row)\n",
    "\n",
    "def display_board(board):\n",
    "\tfor row in board:\n",
    "\t\tprint('  '.join('%5d' % 2**(n - 1) if n > 0 else '  ·  ' for n in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoardEmbeding(torch.nn.Module):\n",
    "\tdef __init__(self, emb_dim=16):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.exp_embedding = torch.nn.Embedding(33, emb_dim)  # assuming max is 2**32\n",
    "\t\tself.pos_x_embedding = torch.nn.Embedding(4, emb_dim)\n",
    "\t\tself.register_buffer('pos_x', torch.arange(4, device=device).repeat(4))\n",
    "\t\tself.pos_y_embedding = torch.nn.Embedding(4, emb_dim)\n",
    "\t\tself.register_buffer('pos_y', torch.arange(4, device=device).repeat_interleave(4))\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\texp_emb = self.exp_embedding(x.flatten(-2))\n",
    "\t\tx_emb = self.pos_x_embedding(self.pos_x)\n",
    "\t\ty_emb = self.pos_y_embedding(self.pos_y)\n",
    "\t\treturn exp_emb + x_emb + y_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(torch.nn.Module):\n",
    "\tdef __init__(self, channels, num_heads, dropout=.1):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.norm1 = torch.nn.LayerNorm(channels)\n",
    "\t\tself.attn = torch.nn.MultiheadAttention(channels, num_heads, dropout)\n",
    "\t\tself.ff = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Linear(channels, 4 * channels),\n",
    "\t\t\ttorch.nn.GELU(),\n",
    "\t\t\ttorch.nn.Linear(4 * channels, channels)\n",
    "\t\t)\n",
    "\t\tself.norm2 = torch.nn.LayerNorm(channels)\n",
    "\t\tself.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.norm1(x)\n",
    "\t\tx = x + self.attn(x, x, x)[0]\n",
    "\t\tx = self.norm2(x)\n",
    "\t\tx = x + self.ff(x)\n",
    "\t\tx = self.dropout(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the policy net: 806,532\n",
      "tensor([-0.9889, -0.3664, -0.2587,  0.6007], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Number of parameters in the value net: 800,385\n",
      "tensor([-0.9474], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class BoardTransformer(torch.nn.Module):\n",
    "\tdef __init__(self, outputs, emb_dim=128, hidden_dim=128, num_blocks=4, num_heads=4):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.embedding = BoardEmbeding(emb_dim)\n",
    "\t\tself.hidden = torch.nn.Sequential(*[TransformerBlock(hidden_dim, num_heads) for _ in range(num_blocks)])\n",
    "\t\tself.out = torch.nn.Linear(16 * hidden_dim, outputs)\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.embedding(x)\n",
    "\t\tx = self.hidden(x)\n",
    "\t\tx = x.flatten(-2)\n",
    "\t\tx = self.out(x)\n",
    "\t\treturn x\n",
    "\n",
    "policy = BoardTransformer(4).to(device)\n",
    "print(f'Number of parameters in the policy net: {sum(p.numel() for p in policy.parameters()):,}')\n",
    "print(policy(new_board()))\n",
    "\n",
    "value = BoardTransformer(1).to(device)\n",
    "print(f'Number of parameters in the value net: {sum(p.numel() for p in value.parameters()):,}')\n",
    "print(value(new_board()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1      2      4      2\n",
      "    8     32     64      4\n",
      "    4     16     32      2\n",
      "    1      2      2      2\n"
     ]
    }
   ],
   "source": [
    "def play_episode(policy, epsilon=1e-5, display=False):\n",
    "\tres = {'states': [], 'logits': [], 'actions': [], 'rewards': []}\n",
    "\tboard = new_board()\n",
    "\tif display: display_board(board)\n",
    "\tturns = 0\n",
    "\twhile True:\n",
    "\t\tlogits = policy(board)\n",
    "\t\tprobs = logits.softmax(-1)\n",
    "\t\ttowards = torch.multinomial(probs + epsilon, 1)\n",
    "\t\tnext_board, changed = push(board, towards.item())\n",
    "\t\tif changed:\n",
    "\t\t\tres['states'].append(board)\n",
    "\t\t\tres['logits'].append(logits)\n",
    "\t\t\tres['actions'].append(towards)\n",
    "\t\t\tres['rewards'].append(1)\n",
    "\t\t\tboard = next_board\n",
    "\t\t\tif display:\n",
    "\t\t\t\tprint('--- moved', ['left', 'up', 'right', 'down'][towards])\n",
    "\t\t\t\tdisplay_board(board)\n",
    "\t\t\tturns += 1\n",
    "\t\t\t# if no moves are possible and no zero is there, the game is over\n",
    "\t\t\tif not (board == 0).any() and not (board[:, :-1] == board[:, 1:]).any() and not (board[:-1] == board[1:]).any(): break\n",
    "\tif display: print('Total turns:', turns)\n",
    "\treturn res\n",
    "\n",
    "history = play_episode(policy)\n",
    "display_board(history['states'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\tdef __init__(self, maxlen):\n",
    "\t\tself.states = torch.empty((maxlen, 16, 4, 4), device=device)\n",
    "\t\tself.actions = torch.empty((maxlen,), dtype=torch.long, device=device)\n",
    "\t\tself.rewards = torch.empty((maxlen,), device=device)\n",
    "\t\tself.logits = torch.empty((maxlen, 4), device=device)\n",
    "\t\tself.append_idx = 0\n",
    "\t\tself.cycled = False\n",
    "\t\n",
    "\tdef append(self, state, action, reward, logits):\n",
    "\t\tself.states[self.append_idx] = state\n",
    "\t\tself.actions[self.append_idx] = action\n",
    "\t\tself.rewards[self.append_idx] = reward\n",
    "\t\tself.logits[self.append_idx] = logits\n",
    "\t\tself.append_idx += 1\n",
    "\t\tif self.append_idx == len(self.states):\n",
    "\t\t\tself.append_idx = 0\n",
    "\t\t\tself.cycled = True\n",
    "\t\n",
    "\tdef sample(self, batch_size):\n",
    "\t\tix = torch.randint(0, len(self.states) if self.cycled else self.append_idx, (batch_size,))\n",
    "\t\treturn self.states[ix], self.actions[ix], self.rewards[ix], self.logits[ix]\n",
    "\n",
    "buffer = ReplayBuffer(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m \t\t\tbuffer\u001b[38;5;241m.\u001b[39mappend(state, action, reward, logits)\n\u001b[0;32m     32\u001b[0m \t\tupdate_policy(policy_net, value_net, buffer, optimizer_policy, optimizer_value)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mtrain_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mtrain_policy\u001b[1;34m(policy_net, value_net, buffer, num_episodes, lr)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state, action, reward, logits \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(episode_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m], episode_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m], episode_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrewards\u001b[39m\u001b[38;5;124m'\u001b[39m], episode_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     31\u001b[0m \tbuffer\u001b[38;5;241m.\u001b[39mappend(state, action, reward, logits)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mupdate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mupdate_policy\u001b[1;34m(policy_net, value_net, buffer, optimizer_policy, optimizer_value, batch_size, epochs, gamma, clip)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      7\u001b[0m \tstates, actions, rewards, logits \u001b[38;5;241m=\u001b[39m buffer\u001b[38;5;241m.\u001b[39msample(batch_size)\n\u001b[1;32m----> 8\u001b[0m \tadvantages \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_advantages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \tlog_probs_old \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, actions\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlog()\n\u001b[0;32m     10\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m state, action, reward, log_prob_old \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(states, actions, rewards, log_probs_old):\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mcompute_advantages\u001b[1;34m(states, rewards, value_net, gamma)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_advantages\u001b[39m(states, rewards, value_net, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m \tvalues \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m rewards \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m values[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m values[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36mBoardTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m \tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden(x)\n\u001b[0;32m     11\u001b[0m \tx \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mBoardEmbeding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m \texp_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \tx_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_x_embedding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_x)\n\u001b[0;32m     13\u001b[0m \ty_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_y_embedding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_y)\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "def compute_advantages(states, rewards, value_net, gamma=0.99):\n",
    "\tvalues = value_net(states)\n",
    "\treturn rewards + gamma * values[1:] - values[:-1]\n",
    "\n",
    "def update_policy(policy_net, value_net, buffer, optimizer_policy, optimizer_value, batch_size=64, epochs=4, gamma=0.99, clip=0.2):\n",
    "\tfor _ in range(epochs):\n",
    "\t\tstates, actions, rewards, logits = buffer.sample(batch_size)\n",
    "\t\tadvantages = compute_advantages(states, rewards, value_net, gamma)\n",
    "\t\tlog_probs_old = logits.gather(1, actions.unsqueeze(-1)).squeeze(-1).log()\n",
    "\t\tfor state, action, reward, log_prob_old in zip(states, actions, rewards, log_probs_old):\n",
    "\t\t\toptimizer_policy.zero_grad()\n",
    "\t\t\toptimizer_value.zero_grad()\n",
    "\t\t\tlogits_new = policy_net(state.unsqueeze(0)).squeeze(0)\n",
    "\t\t\tlog_probs_new = logits_new.gather(0, action).log()\n",
    "\t\t\tratio = (log_probs_new - log_prob_old).exp()\n",
    "\t\t\tsurr1 = ratio * reward\n",
    "\t\t\tsurr2 = torch.clamp(ratio, 1.0 - clip, 1.0 + clip) * reward\n",
    "\t\t\tpolicy_loss = -torch.min(surr1, surr2).mean()\n",
    "\t\t\tpolicy_loss.backward()\n",
    "\t\t\toptimizer_policy.step()\n",
    "\t\t\tvalue_loss = ((value_net(state.unsqueeze(0)) - reward) ** 2).mean()\n",
    "\t\t\tvalue_loss.backward()\n",
    "\t\t\toptimizer_value.step()\n",
    "\n",
    "def train_policy(policy_net, value_net, buffer, num_episodes, lr=1e-4):\n",
    "\toptimizer_policy = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "\toptimizer_value = torch.optim.Adam(value.parameters(), lr=lr)\n",
    "\tfor _ in range(num_episodes):\n",
    "\t\tepisode_data = play_episode(policy_net)\n",
    "\t\tfor state, action, reward, logits in zip(episode_data['states'], episode_data['actions'], episode_data['rewards'], episode_data['logits']):\n",
    "\t\t\tbuffer.append(state, action, reward, logits)\n",
    "\t\tupdate_policy(policy_net, value_net, buffer, optimizer_policy, optimizer_value)\n",
    "\n",
    "train_policy(policy, value, buffer, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
